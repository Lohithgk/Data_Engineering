
# Spark ETL Workflow

This project showcases an extract, transform, and load (ETL) data using PySpark and SparkSQL by adopting a star schema design (with a slight snowflake design on the product side).

## Data Model
Fact Table:
- [Sales.CSV] ()

Dimension Tables:
- Products.CSV
- Product_Subcategories.CSV
- Product_Categories.CSV
- Territories.CSV
- Customers.CSV

Workflow using PySpark
(https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3690907634854246/2866696411247148/8959865570045467/latest.html)

Workflow using SparkSQL
(https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3690907634854246/3201828467364194/8959865570045467/latest.html)
